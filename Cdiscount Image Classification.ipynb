{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sw_H-Gsc9fGe"
   },
   "source": [
    "### %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "### Topic: Cdiscount Image Classification\n",
    "### Author: Siddharth Chandrasekhar\n",
    "### Date: November 2019\n",
    "### %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5xKayDs5L8-7"
   },
   "source": [
    "# **Importing Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3vtJeuI_d3MN"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import bson                       \n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.data import imread  \n",
    "import multiprocessing as mp    \n",
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kxCRzUJDiBxy"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "3Gm2QuFzehV-",
    "outputId": "9ff856ee-78b1-4bcc-98cf-0d20757d5e21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YFz2RyPEO5TJ"
   },
   "outputs": [],
   "source": [
    "# Importing all pytorch related libraries\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vhxJ5K-BMdx4"
   },
   "source": [
    "# **Reading and Processing Category File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n7TLoztYOXTg"
   },
   "outputs": [],
   "source": [
    "catcsv=pd.read_csv('/content/drive/Shared drives/ID576/cdiscount-image-classification-challenge/category_names.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ei197W76O7oe"
   },
   "outputs": [],
   "source": [
    "catcsv=catcsv.drop(['category_level2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VGsk2FBwnDU-"
   },
   "outputs": [],
   "source": [
    "catcsv=catcsv.drop(['category_level3'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qIMecvRdO7eQ"
   },
   "outputs": [],
   "source": [
    "uniquecat=catcsv['category_level1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "colab_type": "code",
    "id": "DhXpJmw7kTZY",
    "outputId": "ba4acebb-a448-40c5-a306-528cc7800a83"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>category_level1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000021794</td>\n",
       "      <td>ABONNEMENT / SERVICES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000012764</td>\n",
       "      <td>AMENAGEMENT URBAIN - VOIRIE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000012776</td>\n",
       "      <td>AMENAGEMENT URBAIN - VOIRIE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000012768</td>\n",
       "      <td>AMENAGEMENT URBAIN - VOIRIE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000012755</td>\n",
       "      <td>AMENAGEMENT URBAIN - VOIRIE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category_id              category_level1\n",
       "0   1000021794        ABONNEMENT / SERVICES\n",
       "1   1000012764  AMENAGEMENT URBAIN - VOIRIE\n",
       "2   1000012776  AMENAGEMENT URBAIN - VOIRIE\n",
       "3   1000012768  AMENAGEMENT URBAIN - VOIRIE\n",
       "4   1000012755  AMENAGEMENT URBAIN - VOIRIE"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catcsv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jO4AsL-MMoF6"
   },
   "source": [
    "# Reading Data from BSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LvJJrDLcfebZ"
   },
   "outputs": [],
   "source": [
    "import bson\n",
    "\n",
    "data = bson.decode_file_iter(open('/content/drive/Shared drives/IDS576/cdiscount-image-classification-challenge/train.bson', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nU9-TNMM-T0g"
   },
   "source": [
    "# Mapping category Names from Category file to Train Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_XptpI4YSO3u"
   },
   "source": [
    "**Mapping Category names to the first batch of files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jbztf3oeDLon"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "temp = itertools.islice(data,0,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L4K2iPgSJNmV"
   },
   "outputs": [],
   "source": [
    "data1=pd.DataFrame(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MAf3RvrfVpSw"
   },
   "source": [
    "**Adding a column with empty values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IhoipxTT0qtD"
   },
   "outputs": [],
   "source": [
    "data1['Category_name']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "colab_type": "code",
    "id": "on-759ZjTkR8",
    "outputId": "d9bad78e-767a-44be-abbe-3660e90bd34b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>imgs</th>\n",
       "      <th>category_id</th>\n",
       "      <th>Category_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[{'picture': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x0...</td>\n",
       "      <td>1000010653</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[{'picture': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x0...</td>\n",
       "      <td>1000010653</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[{'picture': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x0...</td>\n",
       "      <td>1000004079</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[{'picture': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x0...</td>\n",
       "      <td>1000004141</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[{'picture': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x0...</td>\n",
       "      <td>1000015539</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _id  ... Category_name\n",
       "0    0  ...           NaN\n",
       "1    1  ...           NaN\n",
       "2    2  ...           NaN\n",
       "3    3  ...           NaN\n",
       "4    4  ...           NaN\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head() #TO check if the Category_names are empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "colab_type": "code",
    "id": "Y5gjc2k4TgPz",
    "outputId": "a3a4a9f0-230d-4b2a-94b5-81b269ed9be2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "#Code to map category names to our first batch\n",
    "k=-1\n",
    "for i in data1['category_id']:\n",
    "  k=k+1\n",
    "  z=0\n",
    "  for j in catcsv['category_id']:\n",
    "    if i==j:\n",
    "      data1['Category_name'][k]=catcsv['category_level1'][z]\n",
    "      break\n",
    "    z=z+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "colab_type": "code",
    "id": "1TECiEXcUJx2",
    "outputId": "b1e903ed-fd33-434a-ea8f-f7ec3b7bc280"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>imgs</th>\n",
       "      <th>category_id</th>\n",
       "      <th>Category_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[{'picture': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x0...</td>\n",
       "      <td>1000010653</td>\n",
       "      <td>TELEPHONIE - GPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[{'picture': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x0...</td>\n",
       "      <td>1000010653</td>\n",
       "      <td>TELEPHONIE - GPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[{'picture': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x0...</td>\n",
       "      <td>1000004079</td>\n",
       "      <td>INFORMATIQUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[{'picture': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x0...</td>\n",
       "      <td>1000004141</td>\n",
       "      <td>INFORMATIQUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[{'picture': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x0...</td>\n",
       "      <td>1000015539</td>\n",
       "      <td>BRICOLAGE - OUTILLAGE - QUINCAILLERIE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _id  ...                          Category_name\n",
       "0    0  ...                       TELEPHONIE - GPS\n",
       "1    1  ...                       TELEPHONIE - GPS\n",
       "2    2  ...                           INFORMATIQUE\n",
       "3    3  ...                           INFORMATIQUE\n",
       "4    4  ...  BRICOLAGE - OUTILLAGE - QUINCAILLERIE\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head() #Now our data1 has the category names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5omf3sjhT6op"
   },
   "source": [
    "**Defining function to map category names to the rest of the batch and appending to Data1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aBouwuO8xEVQ"
   },
   "outputs": [],
   "source": [
    "num=100\n",
    "seq=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "PaP7lwu_w9xm",
    "outputId": "437fe624-2aa3-4f16-e7d6-51c9916ab4e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "for i in range(num):\n",
    "    temp1=itertools.islice(data,0,seq)\n",
    "    k=-1\n",
    "    print(i)\n",
    "    data2=pd.DataFrame(temp1)\n",
    "    data2['Category_name']=np.nan\n",
    "    for l in data2['category_id']:\n",
    "      k=k+1\n",
    "      z=0\n",
    "      for j in catcsv['category_id']:\n",
    "        if l==j:\n",
    "          data2['Category_name'][k]=catcsv['category_level1'][z]\n",
    "          break\n",
    "        z=z+1\n",
    "    data1=data1.append(data2, ignore_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "DwHoc4wfxQ_l",
    "outputId": "8aede503-967c-4ae6-c6c4-ea8c538740f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101000, 4)"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TQ5ngQzCa5S6"
   },
   "source": [
    "**Making Image Tensors by converting Image file into bytes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R2fU1sVRa434"
   },
   "outputs": [],
   "source": [
    "tensor_pic =[]\n",
    "\n",
    "for i in range(len(data1)):\n",
    "\n",
    "    picture = imread(io.BytesIO(data1['imgs'][i][0]['picture']))\n",
    "    tensor_pic.append(picture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C1aU8vy8crdf"
   },
   "outputs": [],
   "source": [
    "data1['imgs_tensor']=tensor_pic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qKVFg7osdXe0"
   },
   "source": [
    "# **Storing and reading the Data from Pickle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_HnBW3XZOyA"
   },
   "outputs": [],
   "source": [
    "data2_1 = data1[0:25000]\n",
    "data2_1.to_pickle('/content/drive/My Drive/IDS 576/Project/file1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7-9oFiOVZOvP"
   },
   "outputs": [],
   "source": [
    "data2_2 = data1[25000:50000]\n",
    "data2_2.to_pickle('/content/drive/My Drive/IDS 576/Project/file2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FNEkrWCZZOsb"
   },
   "outputs": [],
   "source": [
    "data2_3 = data1[50000:75000]\n",
    "data2_3.to_pickle('/content/drive/My Drive/IDS 576/Project/file3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uUxxCwcQZt3I"
   },
   "outputs": [],
   "source": [
    "data2_4 = data1[75000:100000]\n",
    "data2_4.to_pickle('/content/drive/My Drive/IDS 576/Project/file4.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3cyVyF2F76po"
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "afXnMbfz7pki"
   },
   "outputs": [],
   "source": [
    "p1 = pd.read_pickle('/content/drive/My Drive/IDS 576/Project/file1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6I7wJ7xD7pgA"
   },
   "outputs": [],
   "source": [
    "p2 = pd.read_pickle('/content/drive/My Drive/IDS 576/Project/file2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iNTWSBVY7pCX"
   },
   "outputs": [],
   "source": [
    "p3 = pd.read_pickle('/content/drive/My Drive/IDS 576/Project/file3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VBcsRtv88Eyt"
   },
   "outputs": [],
   "source": [
    "p4 = pd.read_pickle('/content/drive/My Drive/IDS 576/Project/file4.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xFZh-20a8Jr1"
   },
   "outputs": [],
   "source": [
    "pfinal = pd.concat([p1,p2,p3,p4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "TEraXtHA87iq",
    "outputId": "14ff46f0-78bd-448a-da35-b220ab7c2280"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pfinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jY6zq50ILt5P"
   },
   "outputs": [],
   "source": [
    "sample_file = pfinal.head(1000)\n",
    "sample_file.to_csv('/content/drive/My Drive/IDS 576/Project/sample_file.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3nP8aregx3Ox"
   },
   "source": [
    "# Taking only those categories which have more than 2000 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qvyyz05EwFMb"
   },
   "outputs": [],
   "source": [
    "subset_data=pfinal.groupby(\"Category_name\").filter(lambda x: len(x)>2000)\n",
    "#subset_data=pfinal.groupby(\"Category_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "f64p1R6t4Dkf",
    "outputId": "52997747-0740-494b-8e5f-1201422cb650"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81689"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subset_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "id": "Q9rH2WJXxkco",
    "outputId": "646708ab-3aad-4618-c722-6d3a7ac15503"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TELEPHONIE - GPS                         30245\n",
       "INFORMATIQUE                             16918\n",
       "DECO - LINGE - LUMINAIRE                  7157\n",
       "LIBRAIRIE                                 6123\n",
       "AUTO - MOTO                               6120\n",
       "BIJOUX -  LUNETTES - MONTRES              4382\n",
       "BRICOLAGE - OUTILLAGE - QUINCAILLERIE     3083\n",
       "MUSIQUE                                   2921\n",
       "JEUX - JOUETS                             2399\n",
       "ELECTROMENAGER                            2341\n",
       "Name: Category_name, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_data['Category_name'].value_counts() #Counting number of categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kijzyCOVgoJQ"
   },
   "source": [
    "**Now there are 10 Category classes with more than 2000 records**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jI1-5_WUhJRi"
   },
   "source": [
    "**Assigning Integer Labels to each category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_1wwClvAZ5Dg"
   },
   "outputs": [],
   "source": [
    "CatInt=list(set(subset_data['Category_name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "Dj-l0ijp_Xlh",
    "outputId": "21138e8a-f261-4bb5-d08d-b11b1d39c9e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BIJOUX -  LUNETTES - MONTRES',\n",
       " 'LIBRAIRIE',\n",
       " 'MUSIQUE',\n",
       " 'ELECTROMENAGER',\n",
       " 'DECO - LINGE - LUMINAIRE',\n",
       " 'BRICOLAGE - OUTILLAGE - QUINCAILLERIE',\n",
       " 'INFORMATIQUE',\n",
       " 'AUTO - MOTO',\n",
       " 'JEUX - JOUETS',\n",
       " 'TELEPHONIE - GPS']"
      ]
     },
     "execution_count": 615,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CatInt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gaVKQSb03ryd"
   },
   "outputs": [],
   "source": [
    "subset_data_temp = subset_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "csE_P6zGSyou",
    "outputId": "fcb1e2cb-fdd3-4950-8462-361b2680087f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>imgs</th>\n",
       "      <th>category_id</th>\n",
       "      <th>Category_name</th>\n",
       "      <th>imgs_tensor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[{'picture': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x0...</td>\n",
       "      <td>1000010653</td>\n",
       "      <td>TELEPHONIE - GPS</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[{'picture': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x0...</td>\n",
       "      <td>1000010653</td>\n",
       "      <td>TELEPHONIE - GPS</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[{'picture': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x0...</td>\n",
       "      <td>1000004079</td>\n",
       "      <td>INFORMATIQUE</td>\n",
       "      <td>[[[254, 254, 254], [254, 254, 254], [254, 254,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[{'picture': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x0...</td>\n",
       "      <td>1000004141</td>\n",
       "      <td>INFORMATIQUE</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[{'picture': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x0...</td>\n",
       "      <td>1000015539</td>\n",
       "      <td>BRICOLAGE - OUTILLAGE - QUINCAILLERIE</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _id  ...                                        imgs_tensor\n",
       "0    0  ...  [[[255, 255, 255], [255, 255, 255], [255, 255,...\n",
       "1    1  ...  [[[255, 255, 255], [255, 255, 255], [255, 255,...\n",
       "2    2  ...  [[[254, 254, 254], [254, 254, 254], [254, 254,...\n",
       "3    3  ...  [[[255, 255, 255], [255, 255, 255], [255, 255,...\n",
       "4    4  ...  [[[255, 255, 255], [255, 255, 255], [255, 255,...\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fWu1d7UbFOgY"
   },
   "outputs": [],
   "source": [
    "subset_data_temp = subset_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "HYKvh3CYFxuc",
    "outputId": "0fc897d6-8fbb-415f-edb4-e4e704fea4dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id               int64\n",
       "imgs             object\n",
       "category_id       int64\n",
       "Category_name    object\n",
       "imgs_tensor      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eIOkPqPrSpQI"
   },
   "outputs": [],
   "source": [
    "subset_data = subset_data.drop(columns='imgs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_bxoi0SG_fu7"
   },
   "source": [
    "### Map Category names to Category numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jWPsOO3aQ3HV"
   },
   "outputs": [],
   "source": [
    "\n",
    "subset_data['Categ Integer'] = subset_data.apply(lambda x: 0 if x['Category_name']==CatInt[0] else 1 if x['Category_name']==CatInt[1] else 2 if x['Category_name']==CatInt[2] else 3 if x['Category_name']==CatInt[3] else 4 if x['Category_name']==CatInt[4] else 5 if x['Category_name']==CatInt[5] else 6 if x['Category_name']==CatInt[6] else 7 if x['Category_name']==CatInt[7] else 8 if x['Category_name']==CatInt[8] else 9 , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "YRYAyc8gKWCh",
    "outputId": "1c3ce1f1-4973-46fb-d49a-788caf5f4e52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_id', 'category_id', 'Category_name', 'imgs_tensor', 'Categ Integer'], dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "colab_type": "code",
    "id": "XY47KcCoboUv",
    "outputId": "adca41bf-4c09-4733-9d66-21297c7597b9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TELEPHONIE - GPS</th>\n",
       "      <td>30245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INFORMATIQUE</th>\n",
       "      <td>16918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DECO - LINGE - LUMINAIRE</th>\n",
       "      <td>7157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIBRAIRIE</th>\n",
       "      <td>6123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUTO - MOTO</th>\n",
       "      <td>6120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIJOUX -  LUNETTES - MONTRES</th>\n",
       "      <td>4382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BRICOLAGE - OUTILLAGE - QUINCAILLERIE</th>\n",
       "      <td>3083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUSIQUE</th>\n",
       "      <td>2921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JEUX - JOUETS</th>\n",
       "      <td>2399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELECTROMENAGER</th>\n",
       "      <td>2341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Category_name\n",
       "TELEPHONIE - GPS                               30245\n",
       "INFORMATIQUE                                   16918\n",
       "DECO - LINGE - LUMINAIRE                        7157\n",
       "LIBRAIRIE                                       6123\n",
       "AUTO - MOTO                                     6120\n",
       "BIJOUX -  LUNETTES - MONTRES                    4382\n",
       "BRICOLAGE - OUTILLAGE - QUINCAILLERIE           3083\n",
       "MUSIQUE                                         2921\n",
       "JEUX - JOUETS                                   2399\n",
       "ELECTROMENAGER                                  2341"
      ]
     },
     "execution_count": 427,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_data['Category_name'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LLCnb5VGyoKm"
   },
   "source": [
    "# Dividing the Data into Train(80%) and Test(20%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aGW4_EaSZZ7b"
   },
   "source": [
    "**Making separate Dataframes for Data and label**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fbgCk6mzy2xT"
   },
   "outputs": [],
   "source": [
    "X=subset_data['imgs_tensor'] #Image tensors would be XData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dXzunmXRRheF"
   },
   "outputs": [],
   "source": [
    "y = subset_data['Categ Integer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h9sos0VVZoPY"
   },
   "source": [
    "**Spliting Train and Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ezCtSNgKLZkW"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DW1JVFjxaL8H"
   },
   "outputs": [],
   "source": [
    "X_traindata, X_valdata, y_traindata, y_valdata = train_test_split(X, y, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ggaKIRT0RvWr",
    "outputId": "18ada05b-5af6-4842-c1fd-ae59a805a0ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65351,)"
      ]
     },
     "execution_count": 432,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_traindata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "3wec4TDAEcLk",
    "outputId": "8a99c2a2-cbfe-496c-fbc2-bb87d0af11c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 433,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_traindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "id": "9568MMLdFERf",
    "outputId": "aa76f309-6014-4dc5-bfed-5cc68cd568ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9    24230\n",
       "6    13522\n",
       "4     5756\n",
       "7     4926\n",
       "1     4886\n",
       "0     3463\n",
       "5     2419\n",
       "2     2369\n",
       "8     1909\n",
       "3     1871\n",
       "Name: Categ Integer, dtype: int64"
      ]
     },
     "execution_count": 434,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_traindata.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YYfW5rsJImVC"
   },
   "outputs": [],
   "source": [
    "X_traindata = X_traindata.reset_index(drop=True)\n",
    "\n",
    "y_traindata = y_traindata.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2wN0lUY4EakC"
   },
   "outputs": [],
   "source": [
    "x_train_combined = pd.concat([X_traindata,y_traindata],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "3eSpDlcXJO71",
    "outputId": "ba8a0499-02a5-4b82-e410-c21abe26dcd9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imgs_tensor</th>\n",
       "      <th>Categ Integer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[254, 254, 254], [254, 254, 254], [254, 254,...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[238, 238, 238], [230, 230, 230], [232, 232,...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         imgs_tensor  Categ Integer\n",
       "0  [[[254, 254, 254], [254, 254, 254], [254, 254,...              3\n",
       "1  [[[255, 255, 255], [255, 255, 255], [255, 255,...              9\n",
       "2  [[[238, 238, 238], [230, 230, 230], [232, 232,...              9"
      ]
     },
     "execution_count": 438,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_combined.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "colab_type": "code",
    "id": "70-U5Zo1HQry",
    "outputId": "16dfdebe-360f-4b67-94ac-40802ab923b5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imgs_tensor</th>\n",
       "      <th>Categ Integer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[254, 254, 254], [254, 254, 254], [254, 254,...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[238, 238, 238], [230, 230, 230], [232, 232,...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[254, 255, 255], [254, 255, 255], [254, 255,...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[251, 253, 252], [252, 254, 253], [252, 254,...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65347</th>\n",
       "      <td>[[[30, 15, 18], [10, 0, 0], [14, 0, 2], [20, 8...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65348</th>\n",
       "      <td>[[[250, 250, 250], [241, 241, 241], [245, 245,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65349</th>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65350</th>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65351</th>\n",
       "      <td>[[[254, 254, 254], [254, 254, 254], [254, 254,...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65352 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             imgs_tensor  Categ Integer\n",
       "0      [[[254, 254, 254], [254, 254, 254], [254, 254,...              3\n",
       "1      [[[255, 255, 255], [255, 255, 255], [255, 255,...              9\n",
       "2      [[[238, 238, 238], [230, 230, 230], [232, 232,...              9\n",
       "3      [[[254, 255, 255], [254, 255, 255], [254, 255,...              9\n",
       "4      [[[251, 253, 252], [252, 254, 253], [252, 254,...              7\n",
       "...                                                  ...            ...\n",
       "65347  [[[30, 15, 18], [10, 0, 0], [14, 0, 2], [20, 8...              2\n",
       "65348  [[[250, 250, 250], [241, 241, 241], [245, 245,...              2\n",
       "65349  [[[255, 255, 255], [255, 255, 255], [255, 255,...              0\n",
       "65350  [[[255, 255, 255], [255, 255, 255], [255, 255,...              9\n",
       "65351  [[[254, 254, 254], [254, 254, 254], [254, 254,...              3\n",
       "\n",
       "[65352 rows x 2 columns]"
      ]
     },
     "execution_count": 440,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_combined.append(x_train_combined.iloc[0],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fRh6CE7DP-hT"
   },
   "outputs": [],
   "source": [
    "d = {'imgs_tensor':[], 'Categ Integer':[]}\n",
    "x_categ_final = pd.DataFrame(data=d)\n",
    "\n",
    "short_length=0\n",
    "long_length=[]\n",
    "long_label=[]\n",
    "for i in range(10):\n",
    "  x_categ_temp = x_train_combined[x_train_combined['Categ Integer']==i]\n",
    "  x_categ_temp = x_categ_temp.reset_index(drop=True)\n",
    "  if(len(x_categ_temp) <7000):\n",
    "    diff = 7000-len(x_categ_temp)\n",
    "    for j in range(diff):\n",
    "      x_categ_temp = x_categ_temp.append(x_categ_temp.iloc[j])\n",
    "    short_length+=len(x_categ_temp)\n",
    "    x_categ_final = x_categ_final.append(x_categ_temp)\n",
    "  \n",
    "  else:\n",
    "    long_label.append(i)\n",
    "    long_length.append(len(x_categ_temp))\n",
    "  \n",
    "rem_length = 90000-short_length\n",
    "long_length_total  = sum(long_length)\n",
    "\n",
    "for i in range(len(long_label)):\n",
    "  x_categ_temp = x_train_combined[x_train_combined['Categ Integer']==long_label[i]]\n",
    "  x_categ_temp = x_categ_temp.reset_index(drop=True)\n",
    "  size = int((long_length[i]/long_length_total)*rem_length)\n",
    "  x_categ_temp = x_categ_temp[0:size]\n",
    "  x_categ_final = x_categ_final.append(x_categ_temp)\n",
    "\n",
    "  \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IXYqX2zli7VV"
   },
   "outputs": [],
   "source": [
    "x_categ_final_new = x_categ_final.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "McirhHkGkq40"
   },
   "outputs": [],
   "source": [
    "X_traindata = x_categ_final_new['imgs_tensor']\n",
    "y_traindata = x_categ_final_new['Categ Integer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g1gspwgorjL1"
   },
   "outputs": [],
   "source": [
    "type(X_traindata)\n",
    "y_traindata = y_traindata.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "id": "9ucTs4W_rvhP",
    "outputId": "9e077d35-4f6f-48a7-e6bf-a714b349cc71"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9    21821\n",
       "6    12178\n",
       "8     7000\n",
       "7     7000\n",
       "5     7000\n",
       "4     7000\n",
       "3     7000\n",
       "2     7000\n",
       "1     7000\n",
       "0     7000\n",
       "Name: Categ Integer, dtype: int64"
      ]
     },
     "execution_count": 620,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_traindata.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "GL6TA_eHjTmc",
    "outputId": "dea966ca-3330-43d5-805a-c0445a44f075"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9\n",
       "1    8\n",
       "2    0\n",
       "3    6\n",
       "4    6\n",
       "Name: Categ Integer, dtype: int64"
      ]
     },
     "execution_count": 572,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_traindata.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KTx3zztak1g6"
   },
   "source": [
    "**Reindexing the Train, Test & Validation Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KUoPJhs9DQ-N"
   },
   "outputs": [],
   "source": [
    "X_traindata = X_traindata.reset_index(drop=True)\n",
    "X_valdata = X_valdata.reset_index(drop=True)\n",
    "#X_testdata = X_testdata.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r8KRlUxjlCh1"
   },
   "source": [
    " **Resizing 180 * 180 Images to 32 * 32 size for train, test & validation Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6saXvFLZBGps"
   },
   "outputs": [],
   "source": [
    "x_train_data = X_traindata.to_numpy()\n",
    "x_val_data = X_valdata.to_numpy()\n",
    "#x_test_data = X_testdata.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "gIYxe1shBn7_",
    "outputId": "4c538a99-ec42-4618-a420-4cc7d328d936"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 575,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_traindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r11VRJo90zX0"
   },
   "outputs": [],
   "source": [
    "dim = (32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QS688GaaA86I"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "X_traindatare = X_traindata.apply(lambda x:cv2.resize(x, dim, interpolation = cv2.INTER_AREA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "OOio85p79xaf",
    "outputId": "8cfe05c3-767e-4c90-f1d8-78b565f7d690"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 578,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_traindatare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "D0XncFkk8nCv",
    "outputId": "0f56405c-ab4f-4ec5-be23-0164c6d78948"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93752,)"
      ]
     },
     "execution_count": 579,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_traindatare.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gKBf3zRDHsyz"
   },
   "outputs": [],
   "source": [
    "X_valdatare = X_valdata.apply(lambda x:cv2.resize(x, dim, interpolation = cv2.INTER_AREA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 888
    },
    "colab_type": "code",
    "id": "kO909avSHW-c",
    "outputId": "bf4ac894-ddd0-41b0-b61e-9fca4eb62d0f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]]], dtype=uint8)"
      ]
     },
     "execution_count": 582,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valdatare.iloc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zbEOvoasOsCI"
   },
   "outputs": [],
   "source": [
    "ftrain = X_traindatare\n",
    "fval = X_valdatare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "M7FqTWBmpY_V",
    "outputId": "b900ebe1-678c-4927-bf73-261fad1efe34"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 584,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ftrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2iQLUfbkl8Zp"
   },
   "source": [
    "**Converting Train, Test & Validation Data to Numpy Array for Model Input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "3fAUMVx_gWmZ",
    "outputId": "b3dc9ee5-d76f-4080-944b-ab6eb9e194e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 585,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ftrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "jHkf7xg9NX41",
    "outputId": "e437766b-2aa3-4953-eb32-4191cdfbb508"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_data shape: (93752, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train_data = []\n",
    "for myFile in ftrain:\n",
    "    X_train_data.append(myFile)\n",
    "\n",
    "print('X_data shape:', np.array(X_train_data).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "sitk8GosSqlj",
    "outputId": "466a66a7-9f2d-48f4-d364-7b4917762d65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 587,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "So3-wgM0ZWrs"
   },
   "outputs": [],
   "source": [
    "X_train_data2 = np.array(X_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Hg7D0VUhO66H",
    "outputId": "7348bc39-c888-4199-86e9-fa3ec594fba4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_data shape: (16338, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "X_val_data = []\n",
    "for myFile in fval:\n",
    "    X_val_data.append(myFile)\n",
    "\n",
    "print('X_data shape:', np.array(X_val_data).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f8RiVRqKZNRS"
   },
   "outputs": [],
   "source": [
    "X_val_data2 = np.array(X_val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yywz5B2OW5WW"
   },
   "source": [
    "# Converting ALL Numpy arrays to pytorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VrZt3l7DW_iv"
   },
   "outputs": [],
   "source": [
    "#X_train_data2\n",
    "#X_val_data2\n",
    "#X_test_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1wS1FAXtX1sH"
   },
   "outputs": [],
   "source": [
    "#Function to convert a numpy array to pytorch tensor\n",
    "def tensor_convert(f_train):\n",
    "  f_train_tf = torch.from_numpy(f_train)\n",
    "  f_train_tf = f_train_tf.type('torch.FloatTensor')\n",
    "  return f_train_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9nWgYw2JYHa3"
   },
   "outputs": [],
   "source": [
    "x_train_tf = tensor_convert(X_train_data2)\n",
    "x_val_tf = tensor_convert(X_val_data2)\n",
    "#x_test_tf = tensor_convert(X_test_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2-GN4RjfYHLX"
   },
   "outputs": [],
   "source": [
    "#x_test_tf = tensor_convert(X_test_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vUIRA2Q7Ye2o"
   },
   "outputs": [],
   "source": [
    "l_train_tt = torch.from_numpy(np.array(y_traindata))\n",
    "l_val_tt = torch.from_numpy(np.array(y_valdata))\n",
    "#l_test_tt = torch.from_numpy(np.array(y_testdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F5J3YEtPZ6y0"
   },
   "outputs": [],
   "source": [
    "\n",
    "transformations_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "transformations_val = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tSGs-XbjEZR3"
   },
   "outputs": [],
   "source": [
    "trans = transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IRve1tuoZ8FQ"
   },
   "source": [
    "# Modelling using 'Pytorch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "LkRsIB92Z6nt",
    "outputId": "112952c1-1201-4c1e-8393-6e6dae49ff15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n  classifier = nn.Sequential(OrderedDict([\\n      ('fc1', nn.Linear(num_ftrs, 10)),\\n\\n      ('output', nn.LogSoftmax(dim=1))]))\\n  model.fc = classifier\""
      ]
     },
     "execution_count": 598,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vanilla case: Use RESNET with \n",
    "def model_initialize():\n",
    "  #download the Pre-trained RESNET model\n",
    "  import torchvision.models as models\n",
    "  model = models.resnet18(pretrained = True)\n",
    "  \n",
    "  return model\n",
    "\n",
    "def model_freeze(model):\n",
    "  #Freeze the Parameters of RESNET \n",
    "  for param in model.parameters():\n",
    "      param.requires_grad = False \n",
    "\n",
    "  return model\n",
    "\n",
    "\n",
    "\n",
    "def model_last_layer(model):\n",
    "\n",
    "# Since imagenet as 1000 classes , We need to change our last layer to 10 (number of classes we have)\n",
    "  num_ftrs = model.fc.in_features\n",
    "  \n",
    "  classifier = nn.Sequential(OrderedDict([\n",
    "      ('fc1', nn.Linear(num_ftrs, 256)),\n",
    "      ('relu1', nn.ReLU()),\n",
    "      ('fc2', nn.Linear(256, 128)),\n",
    "      ('relu2', nn.ReLU()),\n",
    "      ('fc3', nn.Linear(128,10)),\n",
    "      ('output', nn.LogSoftmax(dim=1))]))\n",
    "  model.fc = classifier\n",
    "  return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "20_mvtxEw7YC"
   },
   "outputs": [],
   "source": [
    "#Initialize Model\n",
    "\n",
    "model_1 = model_initialize()\n",
    "model_1 = model_freeze(model_1)\n",
    "model_1 = model_last_layer(model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "IcFnoSwZFPaD",
    "outputId": "91812705-aeac-4222-9d22-3a7051c802f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (fc1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (relu1): ReLU()\n",
      "    (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (relu2): ReLU()\n",
      "    (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
      "    (output): LogSoftmax()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B8PDdpfdZ6cO"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "model_1.train()\n",
    "optimizer = optim.Adam(model_1.fc.parameters(), lr=0.001)\n",
    "scheduler =  lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "iqZqygeGZ6Qf",
    "outputId": "c6e8fdd5-ea4a-4f56-9c3a-bbb118f1dd89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "#Enable CUDA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "use_cuda = True\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "  model_1.cuda()\n",
    "\n",
    "print('Device:', torch.device('cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "-gdqjz5dZ-57",
    "outputId": "0ecc617e-eed0-4f3b-b07e-7f8e7e90dc6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([93752, 32, 32, 3])"
      ]
     },
     "execution_count": 626,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_train = x_train_tf\n",
    "temp_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tHK-iC38fo7F"
   },
   "outputs": [],
   "source": [
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "xMXq4B3erKJd",
    "outputId": "1c09c70f-3496-46f3-fc47-82b6a44f0c69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Learning Rate : 0.001\n"
     ]
    }
   ],
   "source": [
    "for param_group in optimizer.param_groups:\n",
    "  lr = param_group['lr']\n",
    "  print(\"Initial Learning Rate :\",lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "UT_WQeHwkfXT",
    "outputId": "20426d39-8cf7-470c-ab1d-bbd87910e0e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc in epoch 2 is: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Train acc in epoch {} is: {}\".format(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "-VOoONAx6usd",
    "outputId": "ee406887-9d8d-4910-a3c8-5331b59ea030"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc in epoch 1 is: 31\n",
      "Train acc in epoch 2 is: 34\n",
      "Train acc in epoch 3 is: 35\n",
      "Train acc in epoch 4 is: 35\n",
      "Train acc in epoch 5 is: 36\n",
      "Train acc in epoch 6 is: 37\n",
      "Train acc in epoch 7 is: 37\n",
      "Train acc in epoch 8 is: 37\n",
      "Train acc in epoch 9 is: 37\n",
      "Train acc in epoch 10 is: 37\n",
      "Train acc in epoch 11 is: 37\n",
      "Train acc in epoch 12 is: 37\n",
      "Train acc in epoch 13 is: 37\n",
      "Train acc in epoch 14 is: 37\n",
      "Train acc in epoch 15 is: 37\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size =500\n",
    "model_1.train()\n",
    "for k in range(epochs):\n",
    "  running_acc =0 \n",
    "  if(k==7):\n",
    "    for param_group in optimizer.param_groups:\n",
    "      lr = param_group['lr']\n",
    "\n",
    "    optimizer = optim.SGD(model_1.parameters(), lr=lr,momentum=0.9)    \n",
    "\n",
    "  \n",
    "  \n",
    "\n",
    "  for i in range(int(len(temp_train)/batch_size)):\n",
    "        optimizer.zero_grad()\n",
    "        images_list = []\n",
    "        pre_images = temp_train[batch_size*i:batch_size*i+batch_size]\n",
    "        for j in range(len(pre_images)):\n",
    "          images_list.append(transformations_train(trans(pre_images[j])))\n",
    "        images = torch.stack(images_list)\n",
    "        labels = l_train_tt[batch_size*i:batch_size*i+batch_size]\n",
    "\n",
    "        if use_cuda and torch.cuda.is_available():\n",
    "          images = images.cuda()  \n",
    "          labels = labels.cuda()\n",
    "        model_1.to(device)\n",
    "        log_val = model_1(images)\n",
    "        value,preds = torch.max(log_val, 1)\n",
    "\n",
    "        loss = criterion(log_val,labels)\n",
    "        running_acc+=torch.sum(preds == labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "  scheduler.step()\n",
    "  print(\"Train acc in epoch {} is: {}\".format(k+1,(running_acc*100)/len(temp_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "yMcTDinXTxDH",
    "outputId": "8cf802df-5db2-4504-d738-4453b339147a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
      "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
      "Gen RAM Free: 13.4 GB  | Proc size: 19.9 GB\n",
      "GPU RAM Free: 5893MB | Used: 10387MB | Util  64% | Total 16280MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# memory footprint support libraries/code\n",
    "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "!pip install gputil\n",
    "!pip install psutil\n",
    "!pip install humanize\n",
    "import psutil\n",
    "import humanize\n",
    "import os\n",
    "import GPUtil as GPU\n",
    "GPUs = GPU.getGPUs()\n",
    "# XXX: only one GPU on Colab and isn’t guaranteed\n",
    "gpu = GPUs[0]\n",
    "def printm():\n",
    " process = psutil.Process(os.getpid())\n",
    " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "printm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "jy3d2CYW79kJ",
    "outputId": "754a7ccf-ecc2-47a6-f8b0-2d93d9997759"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "#Intialize count: To calculate number of correctly predicted classes\n",
    "w, h = 1, 10\n",
    "count = [[0 for x in range(w)] for y in range(h)] \n",
    "\n",
    "for i in range(10):\n",
    "  count[i]=0\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kxZ_mlQrkg90"
   },
   "outputs": [],
   "source": [
    "\n",
    "model_1.eval()\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "temp_val = x_val_tf\n",
    "for i in range(int(len(temp_val)/batch_size)):\n",
    "  image_list = []\n",
    "  pre_images = temp_val[batch_size*i:batch_size*i+batch_size]\n",
    "  for j in range(len(pre_images)):\n",
    "    image_list.append(transformations_val(trans(pre_images[j])))\n",
    "  images = torch.stack(image_list)\n",
    "  \n",
    "  images = images.cuda()\n",
    "  labels = l_val_tt[batch_size*i:batch_size*i+batch_size]\n",
    "  labels = labels.cuda()\n",
    "\n",
    "  img_val = model_1(images)\n",
    "  y_pred=[]\n",
    "  for j in range(len(pre_images)):\n",
    "    values, index = torch.max(img_val[j],0)\n",
    "    y_pred.append(index)\n",
    "    if(y_pred[j]==labels[j]):\n",
    "      count[labels[j]]+=1\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "k9qWtF8x7yoI",
    "outputId": "fcce4b8f-662a-4baf-c3d1-2762a88a64f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 43.58550618190721\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation Accuracy: {}\".format((sum(count)*100)/len(x_val_tf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "dW0lVgEU8TAy",
    "outputId": "a08bbb2b-a0af-4dce-b942-e17a7e26589a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIJOUX -  LUNETTES - MONTRES :  0.0\n",
      "LIBRAIRIE :  0.0\n",
      "MUSIQUE :  65.94202898550725\n",
      "ELECTROMENAGER :  21.48936170212766\n",
      "DECO - LINGE - LUMINAIRE :  6.638115631691649\n",
      "BRICOLAGE - OUTILLAGE - QUINCAILLERIE :  0.0\n",
      "INFORMATIQUE :  30.624263839811544\n",
      "AUTO - MOTO :  0.5025125628140703\n",
      "JEUX - JOUETS :  0.20408163265306123\n",
      "TELEPHONIE - GPS :  91.70407315045719\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "  print(CatInt[i],\": \",count[i]/y_valdata.value_counts()[i]*100)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "IDS 576 Final Project.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
